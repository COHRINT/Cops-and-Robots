{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "1. User interface allows generation of utterances\n",
    "2. Mapping user utterance $\\lambda$ to Softmax model (i.e. \"I see the target directly ahead\")\n",
    "  1. Decompose utterence $\\lambda$ to labels: grounding $g_l$, target $t_l$ and relation $r_l$\n",
    "  2. Find categories from labels (i.e. map $t_l$ to $t_c \\in T$, where $T = \\{Roy, Pris, Leon, a\\: robber\\}$\n",
    "    1. Find vector representation of each label\n",
    "    2. Comparie cosine similarity with each category, take most likely\n",
    "  3. Apply SoftMax model $P(L=r_c \\vert x)$, grounded at $g_c$ for target $t_c$ to update probability\n",
    "  \n",
    "\n",
    "## Learning\n",
    "For range modeling:\n",
    "1. Get labeled xy data points (known xy, ask humans for labels)\n",
    "2. Cluster xy data points using k-means (*unknown k - same as # of SoftMax distros* )\n",
    "3. For each cluster, find average of all labels within the cluster (using same method as 2.2 above)\n",
    "4. Given the mean vector for a cluster, assign that token to that cluster as the category\n",
    "\n",
    "## Questions\n",
    "1. How do we select the k in k-means? Can this be a data-driven approach?\n",
    "1. Can we still use nice things like symmetry and polygon constructions to minimize data needed for calibration?\n",
    "1. Are we still talking about calibration, or model generation?\n",
    "1. How do we distinguish single-term prepositions from duo-term prepositions (i.e. 'in front of the door' vs. 'between the pillars')? What about single-term vs. multi-term prepositions (i.e 'in the tree' vs. 'in the trees')?\n",
    "1. If we can only use people, places and things as groundings, does that mean we only need person identification, semantic maps, and object recognition to ground our probabilities?\n",
    "1. If we can use polygon constructions, can we move away from them? Maybe towards occupancy maps, object recognition?\n",
    "1. Upper limit on number of spatial models is number of prepositions. What's a more realistic number of models? Can we come up with a metric for how closely related words like \"near\" and \"nearby\" are physically, to go along with how related they are semantically?\n",
    "1. How do we rigorously extend our SoftMax models to spatio-temporal domain? What examples/use cases could we come up with apart from target-tracking? That is, what motivating examples can we come up with for using humans as sensors in other domains, such as:\n",
    "  * Automated pilot assistants\n",
    "  * Agricultural robotics\n",
    "  * Geology and planetary science\n",
    "  * Emergency response\n",
    "  * Hobby robotics (UAVs, for example)\n",
    "  * Home automation\n",
    "  * Military\n",
    "  * Remote sensing\n",
    "  * Self-driving vehicles\n",
    "  * Space robotics  \n",
    "  * Wilderness search and rescue\n",
    "1. If assessing human use of language, can we approximate humans as any one distribution? Would that distribution be unimodal (i.e. all people generally mean the same thing when saying 'near') or multimodal (i.e. fighter pilots mean something completely different from everyone else when saying 'near')?\n",
    "1. How do we incorporate stateful communication into this? i.e. \"This red ball is important.\" or \"That dog is faster than I am.\"\n",
    "1. Would there be state dynamics associated with the human - especially in terms of attention? How would we come up with models of those dynamics?\n",
    "1. What communication models can we use? How does this relate to the Shannon-Weaver model? More modern ones?\n",
    "1. How do different communication methods (i.e. visual, textual, etc.) impact the communication process?\n",
    "1. How would the communication methods and models impact the robot's state and dynamics? i.e., given a new action space that includes human interaction, how to we model the robot's decision-making?\n",
    "\n",
    "## Notes\n",
    "1. Three main types of uncertainty. Take, \"I am in France,\" as the the sample phase.\n",
    "  1. **Human representation uncertainty:**\n",
    "      Human's uncertainty in properly representing the object. The human may not be correct that she is in France.\n",
    "  1. **Translation uncertainty:** The uncertainty in the communication link. Between two humans, this is often experienced as something like bad cell phone reception, or when speaking with someone in an unfamilliar language.\n",
    "  1. **Robot representation uncertainty:** The robot's uncertainty in representing the object. The robot may think that Belgium is actually named \"France,\" and thus think the human is in Belgium even though it hears France.\n",
    "1. Full list of prepositions according to [Wikipedia](http://en.wikipedia.org/wiki/List_of_English_prepositions) [Grammar Bytes](http://www.chompchomp.com/terms/preposition.htm):\n",
    "  * One Word\n",
    "    * a\n",
    "    * abaft\n",
    "    * abeam\n",
    "    * aboard\n",
    "    * **about**\n",
    "    * **above**\n",
    "    * **absent**\n",
    "    * **across**\n",
    "    * afore\n",
    "    * **after**\n",
    "    * **against**\n",
    "    * **along**\n",
    "    * **alongside**\n",
    "    * **amid**\n",
    "    * **amidst**\n",
    "    * **among**\n",
    "    * **amongst**\n",
    "    * an \n",
    "    * anenst\n",
    "    * apropos \n",
    "    * apud\n",
    "    * **around**\n",
    "    * as \n",
    "    * **aside**\n",
    "    * **astride**\n",
    "    * **at**\n",
    "    * athwart\n",
    "    * **atop**\n",
    "    * barring\n",
    "    * **before**\n",
    "    * **behind**\n",
    "    * **below**\n",
    "    * **beneath**\n",
    "    * **beside**\n",
    "    * **besides**\n",
    "    * **between**\n",
    "    * **beyond**\n",
    "    * but\n",
    "    * **by**\n",
    "    * chez\n",
    "    * circa\n",
    "    * concerning\n",
    "    * despite\n",
    "    * **down**\n",
    "    * during\n",
    "    * except\n",
    "    * excluding\n",
    "    * failing\n",
    "    * **following**\n",
    "    * for\n",
    "    * forenenst\n",
    "    * **from**\n",
    "    * given\n",
    "    * **in**\n",
    "    * including\n",
    "    * **inside**\n",
    "    * **into**\n",
    "    * like\n",
    "    * mid \n",
    "    * midst\n",
    "    * minus\n",
    "    * modulo\n",
    "    * **near** \n",
    "    * next\n",
    "    * notwithstanding\n",
    "    * o' \n",
    "    * of\n",
    "    * **off**\n",
    "    * on\n",
    "    * **onto**\n",
    "    * **opposite**\n",
    "    * **out**\n",
    "    * **outside**\n",
    "    * **over**\n",
    "    * pace\n",
    "    * **past**\n",
    "    * per\n",
    "    * plus\n",
    "    * pro\n",
    "    * qua\n",
    "    * regarding\n",
    "    * round\n",
    "    * sans\n",
    "    * save\n",
    "    * since\n",
    "    * than\n",
    "    * **through, thru **\n",
    "    * **throughout, thruout **\n",
    "    * **till**\n",
    "    * times\n",
    "    * **to**\n",
    "    * **toward**\n",
    "    * **towards**\n",
    "    * **under**\n",
    "    * **underneath**\n",
    "    * unlike\n",
    "    * **until**\n",
    "    * unto\n",
    "    * **up**\n",
    "    * **upon**\n",
    "    * versus, commonly abbreviated as \"vs.\", or (principally in law or sports) as \"v.\"\n",
    "    * **via**\n",
    "    * vice\n",
    "    * vis-Ã -vis\n",
    "    * **with**\n",
    "    * **within**\n",
    "    * **without**\n",
    "    * worth\n",
    "  * Two Word\n",
    "    * according to\n",
    "    * **ahead of**\n",
    "    * **apart from**\n",
    "    * as for\n",
    "    * as of\n",
    "    * as per\n",
    "    * as regards\n",
    "    * **aside from**\n",
    "    * **astern of**\n",
    "    * **back to**\n",
    "    * because of\n",
    "    * **close to**\n",
    "    * due to\n",
    "    * except for\n",
    "    * **far from**\n",
    "    * **in to**\n",
    "    * **inside of**\n",
    "    * instead of\n",
    "    * **left of**\n",
    "    * **near to**\n",
    "    * **next to**\n",
    "    * **on to**\n",
    "    * **opposite of**\n",
    "    * opposite to\n",
    "    * **out from**\n",
    "    * **out of**\n",
    "    * **outside of**\n",
    "    * owing to\n",
    "    * prior to\n",
    "    * pursuant to\n",
    "    * rather than\n",
    "    * regardless of\n",
    "    * **right of**\n",
    "    * **subsequent to**\n",
    "    * such as\n",
    "    * thanks to\n",
    "    * that of\n",
    "    * **up to**\n",
    "  * Three Word\n",
    "    * **as far as**\n",
    "    * **as long as **\n",
    "    * as opposed to\n",
    "    * as soon as\n",
    "    * as well as\n",
    "  * Idiomatic, i.e. Preposition + (article) + noun + preposition\n",
    "    * at the behest of\n",
    "    * by means of\n",
    "    * by virtue of\n",
    "    * for the sake of\n",
    "    * in accordance with\n",
    "    * in addition to\n",
    "    * in case of\n",
    "    * **in front of**\n",
    "    * in lieu of\n",
    "    * in order to\n",
    "    * in place of\n",
    "    * in point of\n",
    "    * in spite of\n",
    "    * on account of\n",
    "    * on behalf of\n",
    "    * **on top of**\n",
    "    * with regard to (sometimes written as \"w/r/t\")\n",
    "    * with respect to\n",
    "    * with a view to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Model\n",
    "    \n",
    "<img src=\"img/sys_model.png\" width=600px>\n",
    "\n",
    "## Block Descriptions\n",
    "**Block** [*domain*]: Description\n",
    "* **Human**\n",
    "  * **Provide Utterance** [*ML*]\n",
    "  * **Receive Request** [*VOI*]\n",
    "* **Autonomous System** \n",
    "  * **Ask for Clarification or Information** [*VOI*]\n",
    "  * **Receive Utterance** [*Signal Processing?*]\n",
    "  * **Parse Utterance** [*NLP*]\n",
    "  * **Ground to Object/Region** [*Data Association, NLP*]\n",
    "  * **Relate to Grounding** [*Spatial Decomposition*]\n",
    "  * **Associate with Target** [*Data Association*]\n",
    "  * **Lidar Update** [*SLAM, ML*]\n",
    "  * **Human Update** [*HRI*]\n",
    "  * **Camera Update** [*Image Processing, Object Recognition*]\n",
    "  * **Data Fusion** [*DF, Estimation*]\n",
    "  * **Target State Estimate** [*Estimation*] \n",
    "  * **Map State Estimate** [*Estimation*]\n",
    "  * **World State Estimate** [*Estimation*]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Roboto:100,100italic,500,300,300italic,400' rel='stylesheet' type='text/css'>\n",
       "\n",
       "<style>\n",
       "    div.cell{\n",
       "        width:800px;\n",
       "        margin-left:16% !important;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    h1, h2, h3, h4 {\n",
       "        font-family: \"Roboto\", \"wingdings\", sans-serif;\n",
       "    }\n",
       "    h1{\n",
       "        font-weight: 500;\n",
       "    }\n",
       "    h2{\n",
       "        font-weight: 400;\n",
       "    }\n",
       "    h3{\n",
       "        font-weight: 300 !important; \n",
       "/*         font-style: italic; */\n",
       "    }    \n",
       "    h4{\n",
       "        font-weight: 300 !important;\n",
       "        font-style: italic;\n",
       "        margin-top:12px;\n",
       "        margin-bottom: 3px;\n",
       "       }\n",
       "    div.text_cell_render{\n",
       "        font-family: \"HelveticaNeue-light\", \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
       "        line-height: 145%;\n",
       "        font-size: 120%;\n",
       "        width:800px;\n",
       "        margin-left:auto;\n",
       "        margin-right:auto;\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "    }\n",
       "    .prompt{\n",
       "        display: None;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 300;\n",
       "        font-size: 22pt;\n",
       "        color: #4057A1;\n",
       "        font-style: italic;\n",
       "        margin-bottom: .5em;\n",
       "        margin-top: 0.5em;\n",
       "        display: block;\n",
       "    }\n",
       "    \n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 )\n",
       "        }  \n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "# Borrowed style from Probabilistic Programming and Bayesian Methods for Hackers\n",
    "def css_styling():\n",
    "    styles = open(\"../styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
